{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB7RPsgyaSPC"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from abc import abstractmethod\n",
    "from typing import Iterable\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkxopJqZaQQp"
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Annotation:\n",
    "    annotator: str\n",
    "    task: str\n",
    "    value: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9lTTnn_aQQs"
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Estimation:\n",
    "    task: str\n",
    "    value: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOBzUXgAaQQw"
   },
   "outputs": [],
   "source": [
    "class TruthInference:\n",
    "    @abstractmethod\n",
    "    def fit(self, annotations: Iterable[Annotation]):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def estimate(self) -> Iterable[Estimation]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFwQz69eaQQz"
   },
   "outputs": [],
   "source": [
    "class DawidSkene(TruthInference):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.predictions_ = {}\n",
    "\n",
    "    def estimate(self) -> Iterable[Estimation]:\n",
    "        return [Estimation(task, val) for task, val in self.predictions_.items()]\n",
    "\n",
    "    def fit(self, annotations: Iterable[Annotation], max_iter=100):\n",
    "        tasks = set(a.task for a in annotations)\n",
    "        task_to_id = {task: i for i, task in enumerate(tasks)}\n",
    "\n",
    "        workers = list(set(a.annotator for a in annotations))\n",
    "        worker_to_id = {worker: i for i, worker in enumerate(workers)}\n",
    "        \n",
    "        values = list(set(a.value for a in annotations))\n",
    "        value_to_id = {value: i for i, value in enumerate(values)}\n",
    "\n",
    "        worker_annotations_values = [[] for _ in workers]\n",
    "        worker_annotations_tasks = [[] for _ in workers]\n",
    "\n",
    "        prediction_distr = np.zeros((len(tasks), len(values)))\n",
    "        for a in annotations:\n",
    "            a_id = worker_to_id[a.annotator]\n",
    "            value_id = value_to_id[a.value]\n",
    "            task_id = task_to_id[a.task]\n",
    "\n",
    "            worker_annotations_values[a_id].append(value_id)\n",
    "            worker_annotations_tasks[a_id].append(task_id)\n",
    "            prediction_distr[task_id, value_id] += 1\n",
    "        prediction_distr = sklearn.preprocessing.normalize(prediction_distr, axis=1, norm='l1')\n",
    "\n",
    "        for i in range(len(worker_to_id)):\n",
    "            worker_annotations_values[i] = np.array(worker_annotations_values[i])\n",
    "            worker_annotations_tasks[i] = np.array(worker_annotations_tasks[i])\n",
    "\n",
    "\n",
    "        prior = np.zeros(len(values))\n",
    "        old_conf_mx = [np.zeros((len(values), len(values))) for _ in workers]\n",
    "\n",
    "        for iter in range(max_iter):\n",
    "            conf_mx = [np.zeros((len(values), len(values))) for _ in workers]\n",
    "            for k in range(len(workers)):\n",
    "                for j in range(len(values)):\n",
    "                    np.add.at(conf_mx[k][:, j], worker_annotations_values[k], prediction_distr[worker_annotations_tasks[k], j])\n",
    "                conf_mx[k] = np.transpose(conf_mx[k])\n",
    "                conf_mx[k] = sklearn.preprocessing.normalize(conf_mx[k], axis=1, norm='l1')\n",
    "\n",
    "            for j in range(len(values)):\n",
    "                prior[j] = np.sum(prediction_distr[:, j]) / len(tasks)\n",
    "            likelihood = np.ones((len(values), len(tasks)))\n",
    "\n",
    "            for k in range(len(workers)):\n",
    "                for j in range(len(values)):\n",
    "                    np.multiply.at(likelihood[j, :], worker_annotations_tasks[k], conf_mx[k][j, worker_annotations_values[k]])\n",
    "            likelihood = np.transpose(likelihood)\n",
    "\n",
    "            logit = 1\n",
    "            for i in range(len(tasks)):\n",
    "                s = 0\n",
    "                for j in range(len(values)):\n",
    "                    prediction_distr[i, j] = prior[j] * likelihood[i, j]\n",
    "                    s += prediction_distr[i, j]\n",
    "                logit += np.log(s)\n",
    "            print(f'Iter {iter:02}, logit: {logit / len(tasks):.6f}')\n",
    "\n",
    "            prediction_distr = sklearn.preprocessing.normalize(prediction_distr, axis=1, norm='l1')\n",
    "\n",
    "            converged = True\n",
    "            for old, new in zip(old_conf_mx, conf_mx):\n",
    "                if np.linalg.norm(old - new) > 0.0001:\n",
    "                    converged = False\n",
    "\n",
    "            if converged:\n",
    "                break\n",
    "\n",
    "            old_conf_mx = conf_mx\n",
    "        self.predictions_ = {t: values[np.argmax(prediction_distr[i, :])] for t, i in task_to_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NNeaDgcaQQ2"
   },
   "outputs": [],
   "source": [
    "class DataProvider:\n",
    "    @abstractmethod\n",
    "    def labels(self) -> Iterable[Annotation]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def gold(self) -> Iterable[Estimation]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUMZw7GiaQQ6"
   },
   "outputs": [],
   "source": [
    "class RelDataProvider(DataProvider):\n",
    "    def __init__(self, path: str):\n",
    "        self._rel_labels = []\n",
    "        self._rel_gold = set()\n",
    "        with open(path, newline='') as csvfile:\n",
    "            file_reader = csv.reader(csvfile, delimiter='\\t')\n",
    "            next(file_reader)\n",
    "            for row in file_reader:\n",
    "                self._rel_labels.append(Annotation(row[1], row[0] + '#' + row[2], row[4]))\n",
    "                gold = row[3]\n",
    "                if gold != '-1':\n",
    "                    self._rel_gold.add(Estimation(row[0] + '#' + row[2], gold))\n",
    "\n",
    "    def labels(self) -> Iterable[Annotation]:\n",
    "        return self._rel_labels\n",
    "\n",
    "    def gold(self) -> Iterable[Estimation]:\n",
    "        return list(self._rel_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Baz1vRAgaQQ9"
   },
   "source": [
    "# Задание: \n",
    "- Реализовать majority vote\n",
    "- Сравнить MV с DS\n",
    "- Выявить \"надежных\"/\"ненадежных\" экспертов\n",
    "- Скольки \"надежным\" экспертам мы не заплатим, если будем платить по совпадению с MV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxALooavaQQ-"
   },
   "outputs": [],
   "source": [
    "class MajorityVote(TruthInference):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predictions_ = {}\n",
    "        \n",
    "        \n",
    "    def estimate(self) -> Iterable[Estimation]:\n",
    "        return [Estimation(task, val) for task, val in self.predictions_.items()]\n",
    "        \n",
    "    \n",
    "    def fit(self, annotations: Iterable[Annotation], max_iter=100):\n",
    "        tasks = set(a.task for a in annotations)\n",
    "        task_to_id = {task: i for i, task in enumerate(tasks)}\n",
    "\n",
    "        workers = list(set(a.annotator for a in annotations))\n",
    "        worker_to_id = {worker: i for i, worker in enumerate(workers)}\n",
    "        \n",
    "        values = list(set(a.value for a in annotations))\n",
    "        value_to_id = {value: i for i, value in enumerate(values)}\n",
    "\n",
    "        task_values = [[] for _ in tasks]\n",
    "        for a in annotations:\n",
    "            task_id = task_to_id[a.task]\n",
    "            task_values[task_id].append(a.value)\n",
    "        self.predictions_ = {t: self.most_freq(task_values[i]) for t, i in task_to_id.items()}\n",
    "    \n",
    "    def most_freq(self, lst):\n",
    "        l = set(lst)\n",
    "        m_fr = max([lst.count(x) for x in l])\n",
    "        candids = [x for x in l if lst.count(x) == m_fr]\n",
    "        if len(candids) == 1:\n",
    "            return candids[0]\n",
    "        else:\n",
    "            return random.choice(candids)\n",
    "\n",
    "        \n",
    "def median(lst):\n",
    "    lst.sort()\n",
    "    return lst[len(lst) // 2]\n",
    "\n",
    "def arith_mean(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu8gfbcVgaYf"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "W_CONF_BOUND = 1.\n",
    "W_SCORE_BOUND = 0.5\n",
    "\n",
    "class ConfidentMajorityVote(MajorityVote):\n",
    "    def __init__(self, scores):\n",
    "        super().__init__()\n",
    "        self.scores = scores\n",
    "        \n",
    "    # scores == {worker : (worker score, our confidence in score)}\n",
    "    def fit(self, annotations: Iterable[Annotation], max_iter=100):\n",
    "        tasks = set(a.task for a in annotations)\n",
    "        task_to_id = {task: i for i, task in enumerate(tasks)}\n",
    "        print(\"Tasks: \" + str(len(tasks)))\n",
    "\n",
    "        workers = list(set(a.annotator for a in annotations))\n",
    "        worker_to_id = {worker: i for i, worker in enumerate(workers)}\n",
    "        \n",
    "        values = list(set(a.value for a in annotations))\n",
    "        value_to_id = {value: i for i, value in enumerate(values)}\n",
    "\n",
    "        conf_task_values = [[] for _ in tasks]\n",
    "        rest_task_values = [[] for _ in tasks]\n",
    "        for a in annotations:\n",
    "            w_score, w_conf = self.scores[a.annotator]\n",
    "            task_id = task_to_id[a.task]\n",
    "            if w_conf < W_CONF_BOUND or w_score < W_SCORE_BOUND:\n",
    "                rest_task_values[task_id].append((a.value, w_score, w_conf))\n",
    "            else:\n",
    "                conf_task_values[task_id].append((a.value, w_score, w_conf))\n",
    "\n",
    "        counter = 0\n",
    "        for t, i in task_to_id.items():\n",
    "            if len(conf_task_values[i]) != 0:\n",
    "                self.predictions_[t] = self.most_freq(conf_task_values[i])\n",
    "            elif len(rest_task_values[i]) != 0:\n",
    "                counter += 1\n",
    "                self.predictions_[t] = self.most_freq(rest_task_values[i])\n",
    "            else:\n",
    "                self.predictions_[t] = random.choice(values)\n",
    "        print(\"No top: \" + str(counter))\n",
    "    \n",
    "    def most_freq(self, lst):\n",
    "        setlst = set([x[0] for x in lst])\n",
    "        weighted_votes = {x : 0. for x in setlst}\n",
    "        for val, sc, conf in lst:\n",
    "            weighted_votes[val] += sc * conf\n",
    "        m_fr = max(weighted_votes.values())\n",
    "        candids = [val for val in weighted_votes if weighted_votes[val] == m_fr]\n",
    "        if len(candids) == 1:\n",
    "            return candids[0]\n",
    "        else:\n",
    "            return random.choice(candids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgoncAubaQRB"
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, worker):\n",
    "        self.worker_ = worker\n",
    "        self.dim_ = 0\n",
    "        self.matrix_ = None\n",
    "        self.gold_numbers_ = []\n",
    "        self.gold_total_ = 0\n",
    "    \n",
    "    def get_by_matrix_normalized(self):\n",
    "        res = self.matrix_.copy()\n",
    "        s = sum(self.gold_numbers_)\n",
    "        if s == 0:\n",
    "            return res\n",
    "        for i in range(self.dim_):\n",
    "            for j in range(self.dim_):\n",
    "                res[i][j] /= s\n",
    "        return res\n",
    "    \n",
    "    def get_by_rows_normalized(self):\n",
    "        if self.matrix_ is None:\n",
    "            return None\n",
    "        res = self.matrix_.copy()\n",
    "        for i in range(self.dim_):\n",
    "            if self.gold_numbers_[i] == 0:\n",
    "                continue\n",
    "            for j in range(self.dim_):\n",
    "                res[i][j] /= self.gold_numbers_[i]\n",
    "        return res\n",
    "        \n",
    "        \n",
    "    def fit(self, annotations: Iterable[Annotation], golds: Iterable[Estimation]):\n",
    "        values = list(set(a.value for a in annotations))\n",
    "        value_to_id_ = {value: i for i, value in enumerate(values)}\n",
    "        self.dim_ = len(values)\n",
    "        self.matrix_ = [[0] * self.dim_ for _ in range(self.dim_)]\n",
    "        self.gold_numbers_ = [0 for _ in range(self.dim_)]\n",
    "        \n",
    "        task_to_gold = {g.task: g.value for g in golds}\n",
    "        \n",
    "        for a in annotations:\n",
    "            if a.annotator != self.worker_ or a.task not in task_to_gold:\n",
    "                continue\n",
    "            v = value_to_id_[a.value]\n",
    "            g = value_to_id_[task_to_gold[a.task]]\n",
    "            self.matrix_[g][v] += 1\n",
    "            self.gold_numbers_[g] += 1\n",
    "            self.gold_total_ += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0WvbfMVaQRP"
   },
   "outputs": [],
   "source": [
    "provider = RelDataProvider('trec-rf10-data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsk9oem6aQRE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2208\n",
      "6.8563825662320665\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "def max_golds_evaluated_by_workers(provider):\n",
    "    workers = list(set(a.annotator for a in provider.labels()))\n",
    "    worker_to_id = {worker: i for i, worker in enumerate(workers)}\n",
    "    task_to_gold = {g.task: g.value for g in provider.gold()}\n",
    "    golds_evaluated = [0 for _ in workers]\n",
    "\n",
    "    for a in provider.labels():\n",
    "        if a.task not in task_to_gold:\n",
    "            continue\n",
    "        golds_evaluated[worker_to_id[a.annotator]] += 1\n",
    "    return golds_evaluated\n",
    "\n",
    "golds_evaluated = max_golds_evaluated_by_workers(provider)\n",
    "non_zeros = [x for x in golds_evaluated if x != 0 ]\n",
    "print(min(golds_evaluated), max(golds_evaluated))\n",
    "print(gmean([x for x in golds_evaluated if x != 0 ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Wqved7raQRJ"
   },
   "outputs": [],
   "source": [
    "class WorkersEvaluator:\n",
    "    \n",
    "    def __init__(self, provider):\n",
    "        self.provider_ = provider\n",
    "        self.workers_ = list(set(a.annotator for a in provider.labels()))\n",
    "\n",
    "        self.matrices_ = [ConfusionMatrix(w) for w in self.workers_]\n",
    "        self.golds_evaluated = []\n",
    "        for m in self.matrices_:\n",
    "            m.fit(provider.labels(), provider.gold())\n",
    "            self.golds_evaluated.append(m.gold_numbers_)\n",
    "        \n",
    "        golds_total = [sum(gs) for gs in self.golds_evaluated]\n",
    "        self.max_golds_ = max(golds_total) # highest confidence score\n",
    "        self.geom_mean_golds = int(gmean([x for x in golds_total if x != 0 ])) # geometric mean among non zeros\n",
    "        \n",
    "        \n",
    "       \n",
    "    # Returns (worker score, our confidence in score) per worker\n",
    "    # confidence in [0., 1.]\n",
    "    # normalize == 'M' => whole confusion matrix is devided by golds numeber\n",
    "    # normalize == 'R' => confusion matrix rows are devided by golds per class\n",
    "    def evaluate_by_trace_sum(self, normalize='M'):\n",
    "        scores = {w : (0., 0.) for w in self.workers_}\n",
    "        \n",
    "        for wid, w in enumerate(self.workers_):\n",
    "            matrix = ConfusionMatrix(w)\n",
    "            matrix.fit(self.provider_.labels(), self.provider_.gold())\n",
    "            m = None\n",
    "            if (normalize == 'M'):\n",
    "                m = matrix.get_by_matrix_normalized()\n",
    "            elif (normalize == 'R'):\n",
    "                m = matrix.get_by_rows_normalized()\n",
    "            sc = 0.\n",
    "            for i in range(len(m)):\n",
    "                sc += m[i][i]\n",
    "            scores[w] = (sc, min(1., sum(self.golds_evaluated[wid]) / self.geom_mean_golds))\n",
    "        return scores\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wf7U6KdgaQRM"
   },
   "outputs": [],
   "source": [
    "def accuracy(provider: DataProvider, inference: TruthInference) -> int:\n",
    "    accepted = 0\n",
    "    all_points = 0\n",
    "    estimates = {}\n",
    "\n",
    "    inference.fit(provider.labels())\n",
    "    for estimate in inference.estimate():\n",
    "        estimates[estimate.task] = estimate.value\n",
    "    for point in provider.gold():\n",
    "        if point.task in estimates:\n",
    "            estimate = estimates[point.task]\n",
    "            all_points += 1\n",
    "            if point.value == estimate:\n",
    "                accepted += 1\n",
    "\n",
    "    accuracy = accepted / all_points\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ5ogRqzaQRS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 00, logit: -3.789689\n",
      "Iter 01, logit: -3.672793\n",
      "Iter 02, logit: -3.635591\n",
      "Iter 03, logit: -3.619169\n",
      "Iter 04, logit: -3.610236\n",
      "Iter 05, logit: -3.604747\n",
      "Iter 06, logit: -3.601037\n",
      "Iter 07, logit: -3.598405\n",
      "Iter 08, logit: -3.596427\n",
      "Iter 09, logit: -3.594798\n",
      "Iter 10, logit: -3.593363\n",
      "Iter 11, logit: -3.592099\n",
      "Iter 12, logit: -3.591016\n",
      "Iter 13, logit: -3.590134\n",
      "Iter 14, logit: -3.589404\n",
      "Iter 15, logit: -3.588847\n",
      "Iter 16, logit: -3.588411\n",
      "Iter 17, logit: -3.588044\n",
      "Iter 18, logit: -3.587721\n",
      "Iter 19, logit: -3.587436\n",
      "Iter 20, logit: -3.587194\n",
      "Iter 21, logit: -3.586989\n",
      "Iter 22, logit: -3.586807\n",
      "Iter 23, logit: -3.586638\n",
      "Iter 24, logit: -3.586475\n",
      "Iter 25, logit: -3.586321\n",
      "Iter 26, logit: -3.586186\n",
      "Iter 27, logit: -3.586064\n",
      "Iter 28, logit: -3.585954\n",
      "Iter 29, logit: -3.585861\n",
      "Iter 30, logit: -3.585782\n",
      "Iter 31, logit: -3.585711\n",
      "Iter 32, logit: -3.585643\n",
      "Iter 33, logit: -3.585578\n",
      "Iter 34, logit: -3.585517\n",
      "Iter 35, logit: -3.585460\n",
      "Iter 36, logit: -3.585403\n",
      "Iter 37, logit: -3.585336\n",
      "Iter 38, logit: -3.585255\n",
      "Iter 39, logit: -3.585174\n",
      "Iter 40, logit: -3.585107\n",
      "Iter 41, logit: -3.585053\n",
      "Iter 42, logit: -3.585005\n",
      "Iter 43, logit: -3.584957\n",
      "Iter 44, logit: -3.584906\n",
      "Iter 45, logit: -3.584860\n",
      "Iter 46, logit: -3.584825\n",
      "Iter 47, logit: -3.584796\n",
      "Iter 48, logit: -3.584770\n",
      "Iter 49, logit: -3.584747\n",
      "Iter 50, logit: -3.584726\n",
      "Iter 51, logit: -3.584706\n",
      "Iter 52, logit: -3.584689\n",
      "Iter 53, logit: -3.584672\n",
      "Iter 54, logit: -3.584656\n",
      "Iter 55, logit: -3.584640\n",
      "Iter 56, logit: -3.584625\n",
      "Iter 57, logit: -3.584609\n",
      "Iter 58, logit: -3.584592\n",
      "Iter 59, logit: -3.584574\n",
      "Iter 60, logit: -3.584556\n",
      "Iter 61, logit: -3.584538\n",
      "Iter 62, logit: -3.584520\n",
      "Iter 63, logit: -3.584504\n",
      "Iter 64, logit: -3.584488\n",
      "Iter 65, logit: -3.584473\n",
      "Iter 66, logit: -3.584458\n",
      "Iter 67, logit: -3.584443\n",
      "Iter 68, logit: -3.584427\n",
      "Iter 69, logit: -3.584409\n",
      "Iter 70, logit: -3.584387\n",
      "Iter 71, logit: -3.584363\n",
      "Iter 72, logit: -3.584336\n",
      "Iter 73, logit: -3.584309\n",
      "Iter 74, logit: -3.584283\n",
      "Iter 75, logit: -3.584261\n",
      "Iter 76, logit: -3.584240\n",
      "Iter 77, logit: -3.584222\n",
      "Iter 78, logit: -3.584207\n",
      "Iter 79, logit: -3.584195\n",
      "Iter 80, logit: -3.584185\n",
      "Iter 81, logit: -3.584177\n",
      "Iter 82, logit: -3.584170\n",
      "Iter 83, logit: -3.584164\n",
      "Iter 84, logit: -3.584158\n",
      "Iter 85, logit: -3.584152\n",
      "Iter 86, logit: -3.584147\n",
      "Iter 87, logit: -3.584141\n",
      "Iter 88, logit: -3.584136\n",
      "Iter 89, logit: -3.584130\n",
      "Iter 90, logit: -3.584124\n",
      "Iter 91, logit: -3.584118\n",
      "Iter 92, logit: -3.584112\n",
      "Iter 93, logit: -3.584105\n",
      "Iter 94, logit: -3.584100\n",
      "Iter 95, logit: -3.584094\n",
      "Iter 96, logit: -3.584089\n",
      "Iter 97, logit: -3.584084\n",
      "Iter 98, logit: -3.584079\n",
      "Iter 99, logit: -3.584075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6143497757847534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(provider, DawidSkene())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whX38suXaQRV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385650224215247"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(provider, MajorityVote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsNJpNTkaQRY"
   },
   "outputs": [],
   "source": [
    "evaluator = WorkersEvaluator(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDCdPOhyaQRb"
   },
   "outputs": [],
   "source": [
    "scores_trace_sum = evaluator.evaluate_by_trace_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcKtbDMmgNrA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks: 20232\n",
      "No top: 945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6468609865470852"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_CONF_BOUND = 0.\n",
    "W_SCORE_BOUND = 0.4\n",
    "accuracy(provider, ConfidentMajorityVote(scores_trace_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXpORLWksmbh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "crowdsourcing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
